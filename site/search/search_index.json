{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Github Link Overview Titan Robot is a ROS 2\u2013based mobile robot platform designed for learning, experimentation, and real-world robotics development. Built with cost efficiency and modularity in mind, Titan Robot enables students, researchers, and developers to explore modern robotic concepts such as autonomous navigation, mapping, localization, and robot software architecture using ROS 2. The platform combines reliable hardware with a flexible software stack, making it suitable for education, prototyping, and research applications. Titan Robot emphasizes hands-on learning by exposing users to both high-level autonomy and low-level motor control. Design Goals Titan Robot was designed with the following goals: Affordability \u2013 Accessible hardware without compromising core robotics capabilities Modularity \u2013 Easy to extend with additional sensors and peripherals ROS 2 Native \u2013 Built entirely around ROS 2 concepts and workflows Educational Focus \u2013 Clear architecture suitable for learning and teaching Real-World Readiness \u2013 Designed to operate reliably outside simulation Key Capabilities Titan Robot supports a wide range of robotics functionalities out of the box: Differential-drive mobile base Real-time motor control with encoder feedback 2D LIDAR-based mapping and obstacle detection Autonomous navigation using ROS 2 Navigation Stack Teleoperation via keyboard or joystick Visualization and debugging using RViz2 Custom firmware and software development Created By Momentum Robotics is an Indian Robotics Startup. Next Steps To begin working with Titan Robot, proceed to: Getting Started \u2013 System requirements and setup Hardware Overview \u2013 Mechanical and electronic design Software Architecture \u2013 ROS 2 node and communication structure Let\u2019s get started \ud83d\ude80","title":"Home"},{"location":"#introduction","text":"Github Link","title":"Introduction"},{"location":"#overview","text":"Titan Robot is a ROS 2\u2013based mobile robot platform designed for learning, experimentation, and real-world robotics development. Built with cost efficiency and modularity in mind, Titan Robot enables students, researchers, and developers to explore modern robotic concepts such as autonomous navigation, mapping, localization, and robot software architecture using ROS 2. The platform combines reliable hardware with a flexible software stack, making it suitable for education, prototyping, and research applications. Titan Robot emphasizes hands-on learning by exposing users to both high-level autonomy and low-level motor control.","title":"Overview"},{"location":"#design-goals","text":"Titan Robot was designed with the following goals: Affordability \u2013 Accessible hardware without compromising core robotics capabilities Modularity \u2013 Easy to extend with additional sensors and peripherals ROS 2 Native \u2013 Built entirely around ROS 2 concepts and workflows Educational Focus \u2013 Clear architecture suitable for learning and teaching Real-World Readiness \u2013 Designed to operate reliably outside simulation","title":"Design Goals"},{"location":"#key-capabilities","text":"Titan Robot supports a wide range of robotics functionalities out of the box: Differential-drive mobile base Real-time motor control with encoder feedback 2D LIDAR-based mapping and obstacle detection Autonomous navigation using ROS 2 Navigation Stack Teleoperation via keyboard or joystick Visualization and debugging using RViz2 Custom firmware and software development","title":"Key Capabilities"},{"location":"#created-by","text":"Momentum Robotics is an Indian Robotics Startup.","title":"Created By"},{"location":"#next-steps","text":"To begin working with Titan Robot, proceed to: Getting Started \u2013 System requirements and setup Hardware Overview \u2013 Mechanical and electronic design Software Architecture \u2013 ROS 2 node and communication structure Let\u2019s get started \ud83d\ude80","title":"Next Steps"},{"location":"about/","text":"About","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"getting-started/","text":"Getting Started Overview This section guides you through the basic requirements and preparation needed to work with Titan Robot . By the end of this section, you will understand the system requirements, robot variants, and how to choose the correct configuration for your use case. System Requirements Titan Robot is designed to run natively on Ubuntu 22.04 LTS with ROS 2 Humble Hawksbill . Supported Operating System Ubuntu 22.04 LTS (64-bit) Required Software ROS 2 Humble Hawksbill (Desktop or Desktop Full) Python 3.10+ It is recommended to install the full ROS 2 desktop version to ensure compatibility with visualization and navigation tools. Supported Robot Variants Titan Robot is available in three hardware variants. Each variant builds on the previous one, adding new sensing and perception capabilities. V1 \u2013 LIDAR-Based Navigation Primary Use Case: Basic autonomous navigation and SLAM Features: - Differential drive mobile base - 2D LIDAR for mapping and obstacle detection - Wheel encoder\u2013based odometry - ROS 2 Navigation Stack support - Keyboard or joystick teleoperation Typical Applications: - Learning ROS 2 navigation - Mapping and localization experiments - Indoor autonomous navigation V2 \u2013 LIDAR + Vision (Pi Camera) Primary Use Case: Autonomous navigation with visual object detection Additional Features over V1: - Raspberry Pi Camera module - Vision-based object detection - Camera integration with ROS 2 image pipeline Typical Applications: - Object detection and tracking - Vision-based robotics projects - AI perception experiments V3 \u2013 LIDAR + Depth Vision (Intel RealSense) Primary Use Case: Advanced perception and 3D-aware navigation Additional Features over V2: - Intel RealSense depth camera - RGB-D perception - Depth-based obstacle understanding - Enhanced perception for autonomy Typical Applications: - 3D perception research - Depth-aware navigation - Advanced autonomous robotics projects Choosing the Right Variant Variant LIDAR Camera Depth Use Case V1 \u2713 \u2717 \u2717 Navigation & SLAM V2 \u2713 Pi Camera \u2717 Navigation + Object Detection V3 \u2713 RealSense \u2713 Advanced Perception & Autonomy Choose the variant that best matches your learning goals or project requirements. You\u2019re now ready to begin working with Titan Robot \ud83d\ude80","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#overview","text":"This section guides you through the basic requirements and preparation needed to work with Titan Robot . By the end of this section, you will understand the system requirements, robot variants, and how to choose the correct configuration for your use case.","title":"Overview"},{"location":"getting-started/#system-requirements","text":"Titan Robot is designed to run natively on Ubuntu 22.04 LTS with ROS 2 Humble Hawksbill .","title":"System Requirements"},{"location":"getting-started/#supported-operating-system","text":"Ubuntu 22.04 LTS (64-bit)","title":"Supported Operating System"},{"location":"getting-started/#required-software","text":"ROS 2 Humble Hawksbill (Desktop or Desktop Full) Python 3.10+ It is recommended to install the full ROS 2 desktop version to ensure compatibility with visualization and navigation tools.","title":"Required Software"},{"location":"getting-started/#supported-robot-variants","text":"Titan Robot is available in three hardware variants. Each variant builds on the previous one, adding new sensing and perception capabilities.","title":"Supported Robot Variants"},{"location":"getting-started/#v1-lidar-based-navigation","text":"Primary Use Case: Basic autonomous navigation and SLAM Features: - Differential drive mobile base - 2D LIDAR for mapping and obstacle detection - Wheel encoder\u2013based odometry - ROS 2 Navigation Stack support - Keyboard or joystick teleoperation Typical Applications: - Learning ROS 2 navigation - Mapping and localization experiments - Indoor autonomous navigation","title":"V1 \u2013 LIDAR-Based Navigation"},{"location":"getting-started/#v2-lidar-vision-pi-camera","text":"Primary Use Case: Autonomous navigation with visual object detection Additional Features over V1: - Raspberry Pi Camera module - Vision-based object detection - Camera integration with ROS 2 image pipeline Typical Applications: - Object detection and tracking - Vision-based robotics projects - AI perception experiments","title":"V2 \u2013 LIDAR + Vision (Pi Camera)"},{"location":"getting-started/#v3-lidar-depth-vision-intel-realsense","text":"Primary Use Case: Advanced perception and 3D-aware navigation Additional Features over V2: - Intel RealSense depth camera - RGB-D perception - Depth-based obstacle understanding - Enhanced perception for autonomy Typical Applications: - 3D perception research - Depth-aware navigation - Advanced autonomous robotics projects","title":"V3 \u2013 LIDAR + Depth Vision (Intel RealSense)"},{"location":"getting-started/#choosing-the-right-variant","text":"Variant LIDAR Camera Depth Use Case V1 \u2713 \u2717 \u2717 Navigation & SLAM V2 \u2713 Pi Camera \u2717 Navigation + Object Detection V3 \u2713 RealSense \u2713 Advanced Perception & Autonomy Choose the variant that best matches your learning goals or project requirements. You\u2019re now ready to begin working with Titan Robot \ud83d\ude80","title":"Choosing the Right Variant"},{"location":"hardware/","text":"Hardware Overview Overview This section describes the complete hardware architecture of Titan Robot , including its mechanical structure, compute units, sensors, electronics, and power system. Hardware Architecture Titan Robot follows a layered hardware design: Compute Layer \u2013 Runs high-level ROS 2 software Control Layer \u2013 Handles real-time motor control and odometry Sensor Layer \u2013 Provides perception and environment awareness Power Layer \u2013 Supplies regulated power to all subsystems Each layer is designed to be independent and modular. Mechanical Design Chassis Differential-drive mobile base Rigid frame with mounting points for: Compute unit Battery Motor controller Sensors Passive caster wheel for balance Compact footprint for indoor navigation Drive System Two DC gear motors Quadrature wheel encoders Rubber wheels for traction Encoder feedback used for odometry and closed-loop control Compute Unit Main Controller Raspberry Pi 4B (8GB RAM) Runs Ubuntu 22.04 LTS Hosts all ROS 2 nodes Handles: SLAM and localization Navigation and planning Perception pipelines User interfaces and visualization Connectivity USB interfaces for sensors and microcontroller WiFi and Ethernet for remote access GPIO headers for expansion Control Electronics Motor Controller (ESP32) ESP32 MCU for real-time control Responsibilities: Motor PWM control PID velocity control Encoder reading Odometry computation Communicates with the compute unit via serial interface Publishes odometry and receives velocity commands through ROS 2 Sensor Suite 2D LIDAR 360\u00b0 scanning range Used for: Mapping (SLAM) Localization Obstacle detection Publishes laser scan data to ROS 2 Camera Systems The camera configuration depends on the robot variant: Variant V1 No camera Navigation relies solely on LIDAR and odometry Variant V2 Raspberry Pi Camera Used for: Object detection Vision-based perception Image processing pipelines Variant V3 Intel RealSense depth camera Provides: RGB images Depth data 3D perception capabilities Power System Battery 11.1V 2500mAh NMC (Lithium Nickel Manganese Cobalt Oxide) Rechargeable lithium-based battery Provides sufficient capacity for extended operation Mounted securely within the chassis Power Distribution Main battery output distributed to: Motor driver circuitry Compute unit via voltage regulator Sensors and peripherals Separate regulated rails to ensure stable operation Voltage Regulation Step-down regulators used to supply: 5V for compute unit and logic Motor voltage as required by motors Designed to handle peak current during motor startup Power Management & Safety Power switch for safe startup and shutdown Inline protection (fuse or current limiter) Reverse polarity and overcurrent protection Charging System Dedicated charging port Charging circuit includes: Overvoltage protection Overcurrent protection Thermal safety mechanisms Expansion & Customization Titan Robot is designed for extensibility: USB ports for additional sensors GPIO access for custom electronics Mounting space for: Extra sensors Displays External controllers This makes the platform suitable for both educational use and advanced research. You now have a complete overview of Titan Robot\u2019s hardware platform \ud83d\ude80","title":"Hardware Architecture"},{"location":"hardware/#hardware-overview","text":"","title":"Hardware Overview"},{"location":"hardware/#overview","text":"This section describes the complete hardware architecture of Titan Robot , including its mechanical structure, compute units, sensors, electronics, and power system.","title":"Overview"},{"location":"hardware/#hardware-architecture","text":"Titan Robot follows a layered hardware design: Compute Layer \u2013 Runs high-level ROS 2 software Control Layer \u2013 Handles real-time motor control and odometry Sensor Layer \u2013 Provides perception and environment awareness Power Layer \u2013 Supplies regulated power to all subsystems Each layer is designed to be independent and modular.","title":"Hardware Architecture"},{"location":"hardware/#mechanical-design","text":"","title":"Mechanical Design"},{"location":"hardware/#chassis","text":"Differential-drive mobile base Rigid frame with mounting points for: Compute unit Battery Motor controller Sensors Passive caster wheel for balance Compact footprint for indoor navigation","title":"Chassis"},{"location":"hardware/#drive-system","text":"Two DC gear motors Quadrature wheel encoders Rubber wheels for traction Encoder feedback used for odometry and closed-loop control","title":"Drive System"},{"location":"hardware/#compute-unit","text":"","title":"Compute Unit"},{"location":"hardware/#main-controller","text":"Raspberry Pi 4B (8GB RAM) Runs Ubuntu 22.04 LTS Hosts all ROS 2 nodes Handles: SLAM and localization Navigation and planning Perception pipelines User interfaces and visualization","title":"Main Controller"},{"location":"hardware/#connectivity","text":"USB interfaces for sensors and microcontroller WiFi and Ethernet for remote access GPIO headers for expansion","title":"Connectivity"},{"location":"hardware/#control-electronics","text":"","title":"Control Electronics"},{"location":"hardware/#motor-controller-esp32","text":"ESP32 MCU for real-time control Responsibilities: Motor PWM control PID velocity control Encoder reading Odometry computation Communicates with the compute unit via serial interface Publishes odometry and receives velocity commands through ROS 2","title":"Motor Controller (ESP32)"},{"location":"hardware/#sensor-suite","text":"","title":"Sensor Suite"},{"location":"hardware/#2d-lidar","text":"360\u00b0 scanning range Used for: Mapping (SLAM) Localization Obstacle detection Publishes laser scan data to ROS 2","title":"2D LIDAR"},{"location":"hardware/#camera-systems","text":"The camera configuration depends on the robot variant:","title":"Camera Systems"},{"location":"hardware/#variant-v1","text":"No camera Navigation relies solely on LIDAR and odometry","title":"Variant V1"},{"location":"hardware/#variant-v2","text":"Raspberry Pi Camera Used for: Object detection Vision-based perception Image processing pipelines","title":"Variant V2"},{"location":"hardware/#variant-v3","text":"Intel RealSense depth camera Provides: RGB images Depth data 3D perception capabilities","title":"Variant V3"},{"location":"hardware/#power-system","text":"","title":"Power System"},{"location":"hardware/#battery","text":"11.1V 2500mAh NMC (Lithium Nickel Manganese Cobalt Oxide) Rechargeable lithium-based battery Provides sufficient capacity for extended operation Mounted securely within the chassis","title":"Battery"},{"location":"hardware/#power-distribution","text":"Main battery output distributed to: Motor driver circuitry Compute unit via voltage regulator Sensors and peripherals Separate regulated rails to ensure stable operation","title":"Power Distribution"},{"location":"hardware/#voltage-regulation","text":"Step-down regulators used to supply: 5V for compute unit and logic Motor voltage as required by motors Designed to handle peak current during motor startup","title":"Voltage Regulation"},{"location":"hardware/#power-management-safety","text":"Power switch for safe startup and shutdown Inline protection (fuse or current limiter) Reverse polarity and overcurrent protection","title":"Power Management &amp; Safety"},{"location":"hardware/#charging-system","text":"Dedicated charging port Charging circuit includes: Overvoltage protection Overcurrent protection Thermal safety mechanisms","title":"Charging System"},{"location":"hardware/#expansion-customization","text":"Titan Robot is designed for extensibility: USB ports for additional sensors GPIO access for custom electronics Mounting space for: Extra sensors Displays External controllers This makes the platform suitable for both educational use and advanced research. You now have a complete overview of Titan Robot\u2019s hardware platform \ud83d\ude80","title":"Expansion &amp; Customization"},{"location":"software/","text":"Software Architecture Overview This section describes the complete software architecture of Titan Robot , including the ROS 2 system running on the main computer and the firmware running on the microcontroller. The software is designed using a layered approach that cleanly separates high-level autonomy from low-level real-time control. Titan Robot uses ROS 2 Humble for all high-level robot functionality and an ESP32 microcontroller programmed using the Arduino IDE for motor control and odometry computation. High-Level Architecture The software stack is divided into two main layers: High-Level ROS 2 Layer (Raspberry Pi) Low-Level Firmware Layer (ESP32) These layers communicate through a serial interface. High-Level ROS 2 Layer (Raspberry Pi) The main computer runs Ubuntu 22.04 with ROS 2 Humble and is responsible for: Robot bringup and system coordination Mapping and localization Autonomous navigation Sensor processing Visualization and user interaction Core ROS 2 Components Robot Bringup Launch files initialize: Robot description (URDF) Sensor drivers ESP32 communication node RViz2 configuration Navigation Stack Uses ROS 2 Navigation (Nav2) Consumes: Odometry data Laser scan data Produces: Velocity commands ( /cmd_vel ) SLAM and Localization SLAM Toolbox used for: Online mapping Localization using pre-built maps Uses laser scans and odometry as inputs Perception (Variant Dependent) V2 : Image pipeline from Pi Camera V3 : RGB-D and depth processing from RealSense camera Used for object detection and advanced perception tasks ROS 2 Communication Interfaces Key Topics Topic Direction Description /cmd_vel Subscribed Velocity commands from navigation or teleop /odom Published Robot odometry from encoder data /scan Published 2D LIDAR scan data /tf Published Coordinate frame transforms /camera/image Published Camera image stream (V2 / V3) Low-Level Firmware Layer (ESP32) Firmware Overview The ESP32 runs custom firmware developed and flashed using the Arduino IDE . Its primary responsibility is real-time motor control and odometry estimation. The firmware operates independently from ROS 2 timing constraints, ensuring stable and deterministic motor behavior. Firmware Responsibilities The ESP32 firmware performs the following tasks: Reads wheel encoder tick counts Computes wheel velocities Applies PID control to motors Computes robot odometry Exchanges data with the Raspberry Pi via serial Odometry Computation Wheel encoders generate tick counts Tick counts are converted to wheel rotation Wheel rotation is used to calculate: Linear displacement Angular displacement Robot pose ( x , y , \u03b8 ) is estimated using differential-drive kinematics Odometry data is sent over serial to the Raspberry Pi Velocity Command Flow Navigation stack or teleop publishes /cmd_vel Raspberry Pi serial node sends velocity commands to ESP32 ESP32: Converts velocity commands to wheel targets Runs PID control loop Updates motor PWM outputs Serial Communication Bidirectional serial communication between ESP32 and Raspberry Pi Data exchanged: Incoming: linear and angular velocity commands Outgoing: odometry and status information Simple, structured protocol for reliability ROS 2 Odometry Publishing On the Raspberry Pi: Serial data is received from ESP32 Encoder-based odometry is decoded Odometry is published as: /odom topic Corresponding TF transforms ( odom \u2192 base_link ) This odometry is then used by: - SLAM Toolbox - Navigation Stack - Visualization tools Timing and Synchronization ESP32 runs control loops at a fixed rate Raspberry Pi handles ROS 2 timing Time stamps are applied on the ROS 2 side Sensor fusion compensates for accumulated odometry error You now have a complete understanding of Titan Robot\u2019s software architecture \ud83d\ude80","title":"Software Architecture"},{"location":"software/#software-architecture","text":"","title":"Software Architecture"},{"location":"software/#overview","text":"This section describes the complete software architecture of Titan Robot , including the ROS 2 system running on the main computer and the firmware running on the microcontroller. The software is designed using a layered approach that cleanly separates high-level autonomy from low-level real-time control. Titan Robot uses ROS 2 Humble for all high-level robot functionality and an ESP32 microcontroller programmed using the Arduino IDE for motor control and odometry computation.","title":"Overview"},{"location":"software/#high-level-architecture","text":"The software stack is divided into two main layers: High-Level ROS 2 Layer (Raspberry Pi) Low-Level Firmware Layer (ESP32) These layers communicate through a serial interface.","title":"High-Level Architecture"},{"location":"software/#high-level-ros-2-layer-raspberry-pi","text":"The main computer runs Ubuntu 22.04 with ROS 2 Humble and is responsible for: Robot bringup and system coordination Mapping and localization Autonomous navigation Sensor processing Visualization and user interaction","title":"High-Level ROS 2 Layer (Raspberry Pi)"},{"location":"software/#core-ros-2-components","text":"","title":"Core ROS 2 Components"},{"location":"software/#robot-bringup","text":"Launch files initialize: Robot description (URDF) Sensor drivers ESP32 communication node RViz2 configuration","title":"Robot Bringup"},{"location":"software/#navigation-stack","text":"Uses ROS 2 Navigation (Nav2) Consumes: Odometry data Laser scan data Produces: Velocity commands ( /cmd_vel )","title":"Navigation Stack"},{"location":"software/#slam-and-localization","text":"SLAM Toolbox used for: Online mapping Localization using pre-built maps Uses laser scans and odometry as inputs","title":"SLAM and Localization"},{"location":"software/#perception-variant-dependent","text":"V2 : Image pipeline from Pi Camera V3 : RGB-D and depth processing from RealSense camera Used for object detection and advanced perception tasks","title":"Perception (Variant Dependent)"},{"location":"software/#ros-2-communication-interfaces","text":"","title":"ROS 2 Communication Interfaces"},{"location":"software/#key-topics","text":"Topic Direction Description /cmd_vel Subscribed Velocity commands from navigation or teleop /odom Published Robot odometry from encoder data /scan Published 2D LIDAR scan data /tf Published Coordinate frame transforms /camera/image Published Camera image stream (V2 / V3)","title":"Key Topics"},{"location":"software/#low-level-firmware-layer-esp32","text":"","title":"Low-Level Firmware Layer (ESP32)"},{"location":"software/#firmware-overview","text":"The ESP32 runs custom firmware developed and flashed using the Arduino IDE . Its primary responsibility is real-time motor control and odometry estimation. The firmware operates independently from ROS 2 timing constraints, ensuring stable and deterministic motor behavior.","title":"Firmware Overview"},{"location":"software/#firmware-responsibilities","text":"The ESP32 firmware performs the following tasks: Reads wheel encoder tick counts Computes wheel velocities Applies PID control to motors Computes robot odometry Exchanges data with the Raspberry Pi via serial","title":"Firmware Responsibilities"},{"location":"software/#odometry-computation","text":"Wheel encoders generate tick counts Tick counts are converted to wheel rotation Wheel rotation is used to calculate: Linear displacement Angular displacement Robot pose ( x , y , \u03b8 ) is estimated using differential-drive kinematics Odometry data is sent over serial to the Raspberry Pi","title":"Odometry Computation"},{"location":"software/#velocity-command-flow","text":"Navigation stack or teleop publishes /cmd_vel Raspberry Pi serial node sends velocity commands to ESP32 ESP32: Converts velocity commands to wheel targets Runs PID control loop Updates motor PWM outputs","title":"Velocity Command Flow"},{"location":"software/#serial-communication","text":"Bidirectional serial communication between ESP32 and Raspberry Pi Data exchanged: Incoming: linear and angular velocity commands Outgoing: odometry and status information Simple, structured protocol for reliability","title":"Serial Communication"},{"location":"software/#ros-2-odometry-publishing","text":"On the Raspberry Pi: Serial data is received from ESP32 Encoder-based odometry is decoded Odometry is published as: /odom topic Corresponding TF transforms ( odom \u2192 base_link ) This odometry is then used by: - SLAM Toolbox - Navigation Stack - Visualization tools","title":"ROS 2 Odometry Publishing"},{"location":"software/#timing-and-synchronization","text":"ESP32 runs control loops at a fixed rate Raspberry Pi handles ROS 2 timing Time stamps are applied on the ROS 2 side Sensor fusion compensates for accumulated odometry error You now have a complete understanding of Titan Robot\u2019s software architecture \ud83d\ude80","title":"Timing and Synchronization"}]}